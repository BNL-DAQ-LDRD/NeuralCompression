python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 1 --benchmark --prefetch_factor 1 --result_fname results/result_0.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 1 --benchmark --prefetch_factor 2 --result_fname results/result_1.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 1 --prefetch_factor 1 --result_fname results/result_2.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 1 --prefetch_factor 2 --result_fname results/result_3.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 2 --benchmark --prefetch_factor 1 --result_fname results/result_4.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 2 --benchmark --prefetch_factor 2 --result_fname results/result_5.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 2 --prefetch_factor 1 --result_fname results/result_6.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 2 --prefetch_factor 2 --result_fname results/result_7.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 3 --benchmark --prefetch_factor 1 --result_fname results/result_8.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 3 --benchmark --prefetch_factor 2 --result_fname results/result_9.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 3 --prefetch_factor 1 --result_fname results/result_10.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 3 --prefetch_factor 2 --result_fname results/result_11.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 4 --benchmark --prefetch_factor 1 --result_fname results/result_12.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 4 --benchmark --prefetch_factor 2 --result_fname results/result_13.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 4 --prefetch_factor 1 --result_fname results/result_14.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 4 --prefetch_factor 2 --result_fname results/result_15.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 6 --benchmark --prefetch_factor 1 --result_fname results/result_16.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 6 --benchmark --prefetch_factor 2 --result_fname results/result_17.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 6 --prefetch_factor 1 --result_fname results/result_18.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 6 --prefetch_factor 2 --result_fname results/result_19.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 8 --benchmark --prefetch_factor 1 --result_fname results/result_20.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 8 --benchmark --prefetch_factor 2 --result_fname results/result_21.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 8 --prefetch_factor 1 --result_fname results/result_22.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 8 --prefetch_factor 2 --result_fname results/result_23.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 12 --benchmark --prefetch_factor 1 --result_fname results/result_24.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 12 --benchmark --prefetch_factor 2 --result_fname results/result_25.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 12 --prefetch_factor 1 --result_fname results/result_26.csv
python gpu_inference.py --data_size 512 --batch_size 2 --pin_memory --num_workers 12 --prefetch_factor 2 --result_fname results/result_27.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 1 --benchmark --prefetch_factor 1 --result_fname results/result_28.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 1 --benchmark --prefetch_factor 2 --result_fname results/result_29.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 1 --prefetch_factor 1 --result_fname results/result_30.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 1 --prefetch_factor 2 --result_fname results/result_31.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 2 --benchmark --prefetch_factor 1 --result_fname results/result_32.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 2 --benchmark --prefetch_factor 2 --result_fname results/result_33.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 2 --prefetch_factor 1 --result_fname results/result_34.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 2 --prefetch_factor 2 --result_fname results/result_35.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 3 --benchmark --prefetch_factor 1 --result_fname results/result_36.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 3 --benchmark --prefetch_factor 2 --result_fname results/result_37.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 3 --prefetch_factor 1 --result_fname results/result_38.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 3 --prefetch_factor 2 --result_fname results/result_39.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 4 --benchmark --prefetch_factor 1 --result_fname results/result_40.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 4 --benchmark --prefetch_factor 2 --result_fname results/result_41.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 4 --prefetch_factor 1 --result_fname results/result_42.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 4 --prefetch_factor 2 --result_fname results/result_43.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 6 --benchmark --prefetch_factor 1 --result_fname results/result_44.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 6 --benchmark --prefetch_factor 2 --result_fname results/result_45.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 6 --prefetch_factor 1 --result_fname results/result_46.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 6 --prefetch_factor 2 --result_fname results/result_47.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 8 --benchmark --prefetch_factor 1 --result_fname results/result_48.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 8 --benchmark --prefetch_factor 2 --result_fname results/result_49.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 8 --prefetch_factor 1 --result_fname results/result_50.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 8 --prefetch_factor 2 --result_fname results/result_51.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 12 --benchmark --prefetch_factor 1 --result_fname results/result_52.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 12 --benchmark --prefetch_factor 2 --result_fname results/result_53.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 12 --prefetch_factor 1 --result_fname results/result_54.csv
python gpu_inference.py --data_size 512 --batch_size 2 --num_workers 12 --prefetch_factor 2 --result_fname results/result_55.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 1 --benchmark --prefetch_factor 1 --result_fname results/result_56.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 1 --benchmark --prefetch_factor 2 --result_fname results/result_57.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 1 --prefetch_factor 1 --result_fname results/result_58.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 1 --prefetch_factor 2 --result_fname results/result_59.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 2 --benchmark --prefetch_factor 1 --result_fname results/result_60.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 2 --benchmark --prefetch_factor 2 --result_fname results/result_61.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 2 --prefetch_factor 1 --result_fname results/result_62.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 2 --prefetch_factor 2 --result_fname results/result_63.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 3 --benchmark --prefetch_factor 1 --result_fname results/result_64.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 3 --benchmark --prefetch_factor 2 --result_fname results/result_65.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 3 --prefetch_factor 1 --result_fname results/result_66.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 3 --prefetch_factor 2 --result_fname results/result_67.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 4 --benchmark --prefetch_factor 1 --result_fname results/result_68.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 4 --benchmark --prefetch_factor 2 --result_fname results/result_69.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 4 --prefetch_factor 1 --result_fname results/result_70.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 4 --prefetch_factor 2 --result_fname results/result_71.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 6 --benchmark --prefetch_factor 1 --result_fname results/result_72.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 6 --benchmark --prefetch_factor 2 --result_fname results/result_73.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 6 --prefetch_factor 1 --result_fname results/result_74.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 6 --prefetch_factor 2 --result_fname results/result_75.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 8 --benchmark --prefetch_factor 1 --result_fname results/result_76.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 8 --benchmark --prefetch_factor 2 --result_fname results/result_77.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 8 --prefetch_factor 1 --result_fname results/result_78.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 8 --prefetch_factor 2 --result_fname results/result_79.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 12 --benchmark --prefetch_factor 1 --result_fname results/result_80.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 12 --benchmark --prefetch_factor 2 --result_fname results/result_81.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 12 --prefetch_factor 1 --result_fname results/result_82.csv
python gpu_inference.py --data_size 512 --batch_size 4 --pin_memory --num_workers 12 --prefetch_factor 2 --result_fname results/result_83.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 1 --benchmark --prefetch_factor 1 --result_fname results/result_84.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 1 --benchmark --prefetch_factor 2 --result_fname results/result_85.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 1 --prefetch_factor 1 --result_fname results/result_86.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 1 --prefetch_factor 2 --result_fname results/result_87.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 2 --benchmark --prefetch_factor 1 --result_fname results/result_88.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 2 --benchmark --prefetch_factor 2 --result_fname results/result_89.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 2 --prefetch_factor 1 --result_fname results/result_90.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 2 --prefetch_factor 2 --result_fname results/result_91.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 3 --benchmark --prefetch_factor 1 --result_fname results/result_92.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 3 --benchmark --prefetch_factor 2 --result_fname results/result_93.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 3 --prefetch_factor 1 --result_fname results/result_94.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 3 --prefetch_factor 2 --result_fname results/result_95.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 4 --benchmark --prefetch_factor 1 --result_fname results/result_96.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 4 --benchmark --prefetch_factor 2 --result_fname results/result_97.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 4 --prefetch_factor 1 --result_fname results/result_98.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 4 --prefetch_factor 2 --result_fname results/result_99.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 6 --benchmark --prefetch_factor 1 --result_fname results/result_100.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 6 --benchmark --prefetch_factor 2 --result_fname results/result_101.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 6 --prefetch_factor 1 --result_fname results/result_102.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 6 --prefetch_factor 2 --result_fname results/result_103.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 8 --benchmark --prefetch_factor 1 --result_fname results/result_104.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 8 --benchmark --prefetch_factor 2 --result_fname results/result_105.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 8 --prefetch_factor 1 --result_fname results/result_106.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 8 --prefetch_factor 2 --result_fname results/result_107.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 12 --benchmark --prefetch_factor 1 --result_fname results/result_108.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 12 --benchmark --prefetch_factor 2 --result_fname results/result_109.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 12 --prefetch_factor 1 --result_fname results/result_110.csv
python gpu_inference.py --data_size 512 --batch_size 4 --num_workers 12 --prefetch_factor 2 --result_fname results/result_111.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 1 --benchmark --prefetch_factor 1 --result_fname results/result_112.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 1 --benchmark --prefetch_factor 2 --result_fname results/result_113.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 1 --prefetch_factor 1 --result_fname results/result_114.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 1 --prefetch_factor 2 --result_fname results/result_115.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 2 --benchmark --prefetch_factor 1 --result_fname results/result_116.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 2 --benchmark --prefetch_factor 2 --result_fname results/result_117.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 2 --prefetch_factor 1 --result_fname results/result_118.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 2 --prefetch_factor 2 --result_fname results/result_119.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 3 --benchmark --prefetch_factor 1 --result_fname results/result_120.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 3 --benchmark --prefetch_factor 2 --result_fname results/result_121.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 3 --prefetch_factor 1 --result_fname results/result_122.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 3 --prefetch_factor 2 --result_fname results/result_123.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 4 --benchmark --prefetch_factor 1 --result_fname results/result_124.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 4 --benchmark --prefetch_factor 2 --result_fname results/result_125.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 4 --prefetch_factor 1 --result_fname results/result_126.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 4 --prefetch_factor 2 --result_fname results/result_127.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 6 --benchmark --prefetch_factor 1 --result_fname results/result_128.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 6 --benchmark --prefetch_factor 2 --result_fname results/result_129.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 6 --prefetch_factor 1 --result_fname results/result_130.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 6 --prefetch_factor 2 --result_fname results/result_131.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 8 --benchmark --prefetch_factor 1 --result_fname results/result_132.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 8 --benchmark --prefetch_factor 2 --result_fname results/result_133.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 8 --prefetch_factor 1 --result_fname results/result_134.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 8 --prefetch_factor 2 --result_fname results/result_135.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 12 --benchmark --prefetch_factor 1 --result_fname results/result_136.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 12 --benchmark --prefetch_factor 2 --result_fname results/result_137.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 12 --prefetch_factor 1 --result_fname results/result_138.csv
python gpu_inference.py --data_size 512 --batch_size 8 --pin_memory --num_workers 12 --prefetch_factor 2 --result_fname results/result_139.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 1 --benchmark --prefetch_factor 1 --result_fname results/result_140.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 1 --benchmark --prefetch_factor 2 --result_fname results/result_141.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 1 --prefetch_factor 1 --result_fname results/result_142.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 1 --prefetch_factor 2 --result_fname results/result_143.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 2 --benchmark --prefetch_factor 1 --result_fname results/result_144.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 2 --benchmark --prefetch_factor 2 --result_fname results/result_145.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 2 --prefetch_factor 1 --result_fname results/result_146.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 2 --prefetch_factor 2 --result_fname results/result_147.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 3 --benchmark --prefetch_factor 1 --result_fname results/result_148.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 3 --benchmark --prefetch_factor 2 --result_fname results/result_149.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 3 --prefetch_factor 1 --result_fname results/result_150.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 3 --prefetch_factor 2 --result_fname results/result_151.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 4 --benchmark --prefetch_factor 1 --result_fname results/result_152.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 4 --benchmark --prefetch_factor 2 --result_fname results/result_153.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 4 --prefetch_factor 1 --result_fname results/result_154.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 4 --prefetch_factor 2 --result_fname results/result_155.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 6 --benchmark --prefetch_factor 1 --result_fname results/result_156.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 6 --benchmark --prefetch_factor 2 --result_fname results/result_157.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 6 --prefetch_factor 1 --result_fname results/result_158.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 6 --prefetch_factor 2 --result_fname results/result_159.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 8 --benchmark --prefetch_factor 1 --result_fname results/result_160.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 8 --benchmark --prefetch_factor 2 --result_fname results/result_161.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 8 --prefetch_factor 1 --result_fname results/result_162.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 8 --prefetch_factor 2 --result_fname results/result_163.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 12 --benchmark --prefetch_factor 1 --result_fname results/result_164.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 12 --benchmark --prefetch_factor 2 --result_fname results/result_165.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 12 --prefetch_factor 1 --result_fname results/result_166.csv
python gpu_inference.py --data_size 512 --batch_size 8 --num_workers 12 --prefetch_factor 2 --result_fname results/result_167.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 1 --benchmark --prefetch_factor 1 --result_fname results/result_168.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 1 --benchmark --prefetch_factor 2 --result_fname results/result_169.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 1 --prefetch_factor 1 --result_fname results/result_170.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 1 --prefetch_factor 2 --result_fname results/result_171.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 2 --benchmark --prefetch_factor 1 --result_fname results/result_172.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 2 --benchmark --prefetch_factor 2 --result_fname results/result_173.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 2 --prefetch_factor 1 --result_fname results/result_174.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 2 --prefetch_factor 2 --result_fname results/result_175.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 3 --benchmark --prefetch_factor 1 --result_fname results/result_176.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 3 --benchmark --prefetch_factor 2 --result_fname results/result_177.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 3 --prefetch_factor 1 --result_fname results/result_178.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 3 --prefetch_factor 2 --result_fname results/result_179.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 4 --benchmark --prefetch_factor 1 --result_fname results/result_180.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 4 --benchmark --prefetch_factor 2 --result_fname results/result_181.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 4 --prefetch_factor 1 --result_fname results/result_182.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 4 --prefetch_factor 2 --result_fname results/result_183.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 6 --benchmark --prefetch_factor 1 --result_fname results/result_184.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 6 --benchmark --prefetch_factor 2 --result_fname results/result_185.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 6 --prefetch_factor 1 --result_fname results/result_186.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 6 --prefetch_factor 2 --result_fname results/result_187.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 8 --benchmark --prefetch_factor 1 --result_fname results/result_188.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 8 --benchmark --prefetch_factor 2 --result_fname results/result_189.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 8 --prefetch_factor 1 --result_fname results/result_190.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 8 --prefetch_factor 2 --result_fname results/result_191.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 12 --benchmark --prefetch_factor 1 --result_fname results/result_192.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 12 --benchmark --prefetch_factor 2 --result_fname results/result_193.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 12 --prefetch_factor 1 --result_fname results/result_194.csv
python gpu_inference.py --data_size 512 --batch_size 16 --pin_memory --num_workers 12 --prefetch_factor 2 --result_fname results/result_195.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 1 --benchmark --prefetch_factor 1 --result_fname results/result_196.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 1 --benchmark --prefetch_factor 2 --result_fname results/result_197.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 1 --prefetch_factor 1 --result_fname results/result_198.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 1 --prefetch_factor 2 --result_fname results/result_199.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 2 --benchmark --prefetch_factor 1 --result_fname results/result_200.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 2 --benchmark --prefetch_factor 2 --result_fname results/result_201.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 2 --prefetch_factor 1 --result_fname results/result_202.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 2 --prefetch_factor 2 --result_fname results/result_203.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 3 --benchmark --prefetch_factor 1 --result_fname results/result_204.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 3 --benchmark --prefetch_factor 2 --result_fname results/result_205.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 3 --prefetch_factor 1 --result_fname results/result_206.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 3 --prefetch_factor 2 --result_fname results/result_207.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 4 --benchmark --prefetch_factor 1 --result_fname results/result_208.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 4 --benchmark --prefetch_factor 2 --result_fname results/result_209.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 4 --prefetch_factor 1 --result_fname results/result_210.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 4 --prefetch_factor 2 --result_fname results/result_211.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 6 --benchmark --prefetch_factor 1 --result_fname results/result_212.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 6 --benchmark --prefetch_factor 2 --result_fname results/result_213.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 6 --prefetch_factor 1 --result_fname results/result_214.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 6 --prefetch_factor 2 --result_fname results/result_215.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 8 --benchmark --prefetch_factor 1 --result_fname results/result_216.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 8 --benchmark --prefetch_factor 2 --result_fname results/result_217.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 8 --prefetch_factor 1 --result_fname results/result_218.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 8 --prefetch_factor 2 --result_fname results/result_219.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 12 --benchmark --prefetch_factor 1 --result_fname results/result_220.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 12 --benchmark --prefetch_factor 2 --result_fname results/result_221.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 12 --prefetch_factor 1 --result_fname results/result_222.csv
python gpu_inference.py --data_size 512 --batch_size 16 --num_workers 12 --prefetch_factor 2 --result_fname results/result_223.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 1 --benchmark --prefetch_factor 1 --result_fname results/result_224.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 1 --benchmark --prefetch_factor 2 --result_fname results/result_225.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 1 --prefetch_factor 1 --result_fname results/result_226.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 1 --prefetch_factor 2 --result_fname results/result_227.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 2 --benchmark --prefetch_factor 1 --result_fname results/result_228.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 2 --benchmark --prefetch_factor 2 --result_fname results/result_229.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 2 --prefetch_factor 1 --result_fname results/result_230.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 2 --prefetch_factor 2 --result_fname results/result_231.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 3 --benchmark --prefetch_factor 1 --result_fname results/result_232.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 3 --benchmark --prefetch_factor 2 --result_fname results/result_233.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 3 --prefetch_factor 1 --result_fname results/result_234.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 3 --prefetch_factor 2 --result_fname results/result_235.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 4 --benchmark --prefetch_factor 1 --result_fname results/result_236.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 4 --benchmark --prefetch_factor 2 --result_fname results/result_237.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 4 --prefetch_factor 1 --result_fname results/result_238.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 4 --prefetch_factor 2 --result_fname results/result_239.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 6 --benchmark --prefetch_factor 1 --result_fname results/result_240.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 6 --benchmark --prefetch_factor 2 --result_fname results/result_241.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 6 --prefetch_factor 1 --result_fname results/result_242.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 6 --prefetch_factor 2 --result_fname results/result_243.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 8 --benchmark --prefetch_factor 1 --result_fname results/result_244.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 8 --benchmark --prefetch_factor 2 --result_fname results/result_245.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 8 --prefetch_factor 1 --result_fname results/result_246.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 8 --prefetch_factor 2 --result_fname results/result_247.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 12 --benchmark --prefetch_factor 1 --result_fname results/result_248.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 12 --benchmark --prefetch_factor 2 --result_fname results/result_249.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 12 --prefetch_factor 1 --result_fname results/result_250.csv
python gpu_inference.py --data_size 512 --batch_size 32 --pin_memory --num_workers 12 --prefetch_factor 2 --result_fname results/result_251.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 1 --benchmark --prefetch_factor 1 --result_fname results/result_252.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 1 --benchmark --prefetch_factor 2 --result_fname results/result_253.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 1 --prefetch_factor 1 --result_fname results/result_254.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 1 --prefetch_factor 2 --result_fname results/result_255.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 2 --benchmark --prefetch_factor 1 --result_fname results/result_256.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 2 --benchmark --prefetch_factor 2 --result_fname results/result_257.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 2 --prefetch_factor 1 --result_fname results/result_258.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 2 --prefetch_factor 2 --result_fname results/result_259.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 3 --benchmark --prefetch_factor 1 --result_fname results/result_260.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 3 --benchmark --prefetch_factor 2 --result_fname results/result_261.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 3 --prefetch_factor 1 --result_fname results/result_262.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 3 --prefetch_factor 2 --result_fname results/result_263.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 4 --benchmark --prefetch_factor 1 --result_fname results/result_264.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 4 --benchmark --prefetch_factor 2 --result_fname results/result_265.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 4 --prefetch_factor 1 --result_fname results/result_266.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 4 --prefetch_factor 2 --result_fname results/result_267.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 6 --benchmark --prefetch_factor 1 --result_fname results/result_268.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 6 --benchmark --prefetch_factor 2 --result_fname results/result_269.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 6 --prefetch_factor 1 --result_fname results/result_270.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 6 --prefetch_factor 2 --result_fname results/result_271.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 8 --benchmark --prefetch_factor 1 --result_fname results/result_272.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 8 --benchmark --prefetch_factor 2 --result_fname results/result_273.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 8 --prefetch_factor 1 --result_fname results/result_274.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 8 --prefetch_factor 2 --result_fname results/result_275.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 12 --benchmark --prefetch_factor 1 --result_fname results/result_276.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 12 --benchmark --prefetch_factor 2 --result_fname results/result_277.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 12 --prefetch_factor 1 --result_fname results/result_278.csv
python gpu_inference.py --data_size 512 --batch_size 32 --num_workers 12 --prefetch_factor 2 --result_fname results/result_279.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 1 --benchmark --prefetch_factor 1 --result_fname results/result_280.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 1 --benchmark --prefetch_factor 2 --result_fname results/result_281.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 1 --prefetch_factor 1 --result_fname results/result_282.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 1 --prefetch_factor 2 --result_fname results/result_283.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 2 --benchmark --prefetch_factor 1 --result_fname results/result_284.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 2 --benchmark --prefetch_factor 2 --result_fname results/result_285.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 2 --prefetch_factor 1 --result_fname results/result_286.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 2 --prefetch_factor 2 --result_fname results/result_287.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 3 --benchmark --prefetch_factor 1 --result_fname results/result_288.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 3 --benchmark --prefetch_factor 2 --result_fname results/result_289.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 3 --prefetch_factor 1 --result_fname results/result_290.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 3 --prefetch_factor 2 --result_fname results/result_291.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 4 --benchmark --prefetch_factor 1 --result_fname results/result_292.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 4 --benchmark --prefetch_factor 2 --result_fname results/result_293.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 4 --prefetch_factor 1 --result_fname results/result_294.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 4 --prefetch_factor 2 --result_fname results/result_295.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 6 --benchmark --prefetch_factor 1 --result_fname results/result_296.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 6 --benchmark --prefetch_factor 2 --result_fname results/result_297.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 6 --prefetch_factor 1 --result_fname results/result_298.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 6 --prefetch_factor 2 --result_fname results/result_299.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 8 --benchmark --prefetch_factor 1 --result_fname results/result_300.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 8 --benchmark --prefetch_factor 2 --result_fname results/result_301.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 8 --prefetch_factor 1 --result_fname results/result_302.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 8 --prefetch_factor 2 --result_fname results/result_303.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 12 --benchmark --prefetch_factor 1 --result_fname results/result_304.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 12 --benchmark --prefetch_factor 2 --result_fname results/result_305.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 12 --prefetch_factor 1 --result_fname results/result_306.csv
python gpu_inference.py --data_size 512 --batch_size 64 --pin_memory --num_workers 12 --prefetch_factor 2 --result_fname results/result_307.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 1 --benchmark --prefetch_factor 1 --result_fname results/result_308.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 1 --benchmark --prefetch_factor 2 --result_fname results/result_309.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 1 --prefetch_factor 1 --result_fname results/result_310.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 1 --prefetch_factor 2 --result_fname results/result_311.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 2 --benchmark --prefetch_factor 1 --result_fname results/result_312.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 2 --benchmark --prefetch_factor 2 --result_fname results/result_313.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 2 --prefetch_factor 1 --result_fname results/result_314.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 2 --prefetch_factor 2 --result_fname results/result_315.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 3 --benchmark --prefetch_factor 1 --result_fname results/result_316.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 3 --benchmark --prefetch_factor 2 --result_fname results/result_317.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 3 --prefetch_factor 1 --result_fname results/result_318.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 3 --prefetch_factor 2 --result_fname results/result_319.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 4 --benchmark --prefetch_factor 1 --result_fname results/result_320.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 4 --benchmark --prefetch_factor 2 --result_fname results/result_321.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 4 --prefetch_factor 1 --result_fname results/result_322.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 4 --prefetch_factor 2 --result_fname results/result_323.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 6 --benchmark --prefetch_factor 1 --result_fname results/result_324.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 6 --benchmark --prefetch_factor 2 --result_fname results/result_325.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 6 --prefetch_factor 1 --result_fname results/result_326.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 6 --prefetch_factor 2 --result_fname results/result_327.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 8 --benchmark --prefetch_factor 1 --result_fname results/result_328.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 8 --benchmark --prefetch_factor 2 --result_fname results/result_329.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 8 --prefetch_factor 1 --result_fname results/result_330.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 8 --prefetch_factor 2 --result_fname results/result_331.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 12 --benchmark --prefetch_factor 1 --result_fname results/result_332.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 12 --benchmark --prefetch_factor 2 --result_fname results/result_333.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 12 --prefetch_factor 1 --result_fname results/result_334.csv
python gpu_inference.py --data_size 512 --batch_size 64 --num_workers 12 --prefetch_factor 2 --result_fname results/result_335.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 1 --benchmark --prefetch_factor 1 --result_fname results/result_336.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 1 --benchmark --prefetch_factor 2 --result_fname results/result_337.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 1 --prefetch_factor 1 --result_fname results/result_338.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 1 --prefetch_factor 2 --result_fname results/result_339.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 2 --benchmark --prefetch_factor 1 --result_fname results/result_340.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 2 --benchmark --prefetch_factor 2 --result_fname results/result_341.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 2 --prefetch_factor 1 --result_fname results/result_342.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 2 --prefetch_factor 2 --result_fname results/result_343.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 3 --benchmark --prefetch_factor 1 --result_fname results/result_344.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 3 --benchmark --prefetch_factor 2 --result_fname results/result_345.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 3 --prefetch_factor 1 --result_fname results/result_346.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 3 --prefetch_factor 2 --result_fname results/result_347.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 4 --benchmark --prefetch_factor 1 --result_fname results/result_348.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 4 --benchmark --prefetch_factor 2 --result_fname results/result_349.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 4 --prefetch_factor 1 --result_fname results/result_350.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 4 --prefetch_factor 2 --result_fname results/result_351.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 6 --benchmark --prefetch_factor 1 --result_fname results/result_352.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 6 --benchmark --prefetch_factor 2 --result_fname results/result_353.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 6 --prefetch_factor 1 --result_fname results/result_354.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 6 --prefetch_factor 2 --result_fname results/result_355.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 8 --benchmark --prefetch_factor 1 --result_fname results/result_356.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 8 --benchmark --prefetch_factor 2 --result_fname results/result_357.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 8 --prefetch_factor 1 --result_fname results/result_358.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 8 --prefetch_factor 2 --result_fname results/result_359.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 12 --benchmark --prefetch_factor 1 --result_fname results/result_360.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 12 --benchmark --prefetch_factor 2 --result_fname results/result_361.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 12 --prefetch_factor 1 --result_fname results/result_362.csv
python gpu_inference.py --data_size 512 --batch_size 128 --pin_memory --num_workers 12 --prefetch_factor 2 --result_fname results/result_363.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 1 --benchmark --prefetch_factor 1 --result_fname results/result_364.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 1 --benchmark --prefetch_factor 2 --result_fname results/result_365.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 1 --prefetch_factor 1 --result_fname results/result_366.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 1 --prefetch_factor 2 --result_fname results/result_367.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 2 --benchmark --prefetch_factor 1 --result_fname results/result_368.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 2 --benchmark --prefetch_factor 2 --result_fname results/result_369.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 2 --prefetch_factor 1 --result_fname results/result_370.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 2 --prefetch_factor 2 --result_fname results/result_371.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 3 --benchmark --prefetch_factor 1 --result_fname results/result_372.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 3 --benchmark --prefetch_factor 2 --result_fname results/result_373.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 3 --prefetch_factor 1 --result_fname results/result_374.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 3 --prefetch_factor 2 --result_fname results/result_375.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 4 --benchmark --prefetch_factor 1 --result_fname results/result_376.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 4 --benchmark --prefetch_factor 2 --result_fname results/result_377.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 4 --prefetch_factor 1 --result_fname results/result_378.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 4 --prefetch_factor 2 --result_fname results/result_379.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 6 --benchmark --prefetch_factor 1 --result_fname results/result_380.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 6 --benchmark --prefetch_factor 2 --result_fname results/result_381.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 6 --prefetch_factor 1 --result_fname results/result_382.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 6 --prefetch_factor 2 --result_fname results/result_383.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 8 --benchmark --prefetch_factor 1 --result_fname results/result_384.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 8 --benchmark --prefetch_factor 2 --result_fname results/result_385.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 8 --prefetch_factor 1 --result_fname results/result_386.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 8 --prefetch_factor 2 --result_fname results/result_387.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 12 --benchmark --prefetch_factor 1 --result_fname results/result_388.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 12 --benchmark --prefetch_factor 2 --result_fname results/result_389.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 12 --prefetch_factor 1 --result_fname results/result_390.csv
python gpu_inference.py --data_size 512 --batch_size 128 --num_workers 12 --prefetch_factor 2 --result_fname results/result_391.csv